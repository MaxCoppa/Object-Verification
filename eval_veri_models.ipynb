{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset_annotation_preparation import prepare_annotation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from training_evaluation import (\n",
    "    test_model,\n",
    ")\n",
    "\n",
    "from utils import image_utils, model_utils\n",
    "\n",
    "from dataset_preloader import VeriImageDatasetTest\n",
    "\n",
    "from veri_models import ObjectVeriSiamese, ModelEnsembler\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Import project configuration\n",
    "from config import ANNOTATIONS_PATH, RAW_ANNOTATIONS_PATH, DATA_PATH, MODELS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectVeriSiamese(backbone=\"mobilenet_v3_small\")\n",
    "model.load_state_dict(torch.load(MODELS_PATH / \"model_2.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Ensembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ObjectVeriSiamese()\n",
    "model1.load_state_dict(torch.load(MODELS_PATH / \"model_1.pth\"))\n",
    "\n",
    "model2 = ObjectVeriSiamese(backbone=\"mobilenet_v3_small\")\n",
    "model2.load_state_dict(torch.load(MODELS_PATH / \"model_2.pth\"))\n",
    "\n",
    "\n",
    "model = ModelEnsembler(\n",
    "    models=[\n",
    "        model1,\n",
    "        model2,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Save .pt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = MODELS_PATH / \"model_veri_eval.pt\"\n",
    "torch.save(model, PATH)\n",
    "model = torch.load(PATH, weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% -------------------------\n",
    "# Define parameters\n",
    "# -------------------------\n",
    "train_ratio = 0.5\n",
    "n_error = 2\n",
    "n_augmentation = 5\n",
    "\n",
    "load = True\n",
    "\n",
    "transform_type_val = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_annotation_sharks = RAW_ANNOTATIONS_PATH / \"raw_annotations_sharks.csv\"\n",
    "preprocessed_annotation_sharks = (\n",
    "    ANNOTATIONS_PATH / \"preprocessed_annotations_sharks.csv\"\n",
    ")\n",
    "\n",
    "raw_annotation_birds = RAW_ANNOTATIONS_PATH / \"raw_annotations_birds.csv\"\n",
    "preprocessed_annotation_birds = ANNOTATIONS_PATH / \"preprocessed_annotations_birds.csv\"\n",
    "\n",
    "images_dir = DATA_PATH / \"animals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = prepare_annotation(\n",
    "    raw_annotation_path=raw_annotation_birds,\n",
    "    images_dir=images_dir,\n",
    "    preprocessed_annotation_path=preprocessed_annotation_birds,\n",
    "    train_ratio=0,\n",
    "    n_augmentation=n_augmentation,\n",
    "    n_error=n_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = image_utils.transform_fc(transform_type_val)\n",
    "\n",
    "test_data = VeriImageDatasetTest(\n",
    "    annotations_file=preprocessed_annotation_birds,\n",
    "    transform=transform_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.visualize_images(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotation, results, quartiles_results, FRR_results = test_model(\n",
    "    model, test_dataloader, print_results=True, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_scores = (\n",
    "    df_annotation[\"label\"].to_numpy(),\n",
    "    df_annotation[\"distance\"].to_numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_roc_curve(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_score_distributions(y_true, y_scores, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df_annotation.sample(frac=1).reset_index(drop=True)\n",
    "df_error = df_shuffled[\n",
    "    (1 == df_shuffled[\"label\"]) & (df_shuffled[\"distance\"] <= 0.95)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotation_init = pd.read_csv(preprocessed_annotation_birds)\n",
    "\n",
    "df_error_merged = df_error.merge(\n",
    "    df_annotation_init[\n",
    "        [\n",
    "            col\n",
    "            for col in df_annotation_init.columns\n",
    "            if col not in df_error.columns or col in [\"img_path\", \"couple_path\"]\n",
    "        ]\n",
    "    ],\n",
    "    on=[\"img_path\", \"couple_path\"],\n",
    ")\n",
    "\n",
    "# df_error_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_utils.visualise_images_df(\n",
    "    df=df_error_merged,\n",
    "    n_images=1,\n",
    "    file_type=\"jpg\",\n",
    "    crop_type=None,\n",
    "    debug=True,\n",
    "    transform_type=\"same\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
